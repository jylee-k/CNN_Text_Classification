{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BiLSTMSentiment(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_model, vocab_size, label_size, embedding_dim, hidden_dim, batch_size, seq_length, num_layers, dropout=0.5, freeze_embeddings = True):\n",
    "        super(BiLSTMSentiment, self).__init__()\n",
    "        # set class vars\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # 1. embedding layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # set weights to pre-trained\n",
    "        self.embeddings.weight = nn.Parameter(torch.from_numpy(embed_model.vectors)) # all vectors\n",
    "        # (optional) freeze embedding weights\n",
    "        if freeze_embeddings:\n",
    "            self.embeddings.requires_grad = False\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(batch_first=True, input_size=embedding_dim, num_layers =num_layers, hidden_size=hidden_dim, bidirectional=True)\n",
    "        self.hidden2label = nn.Linear(hidden_dim*2, label_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # print(sentence.shape)\n",
    "        x = self.embeddings(sentence)\n",
    "        batch_size = sentence.shape[0]\n",
    "        # print(x.shape)\n",
    "        _, (lstm_hidden, _) = self.lstm(x)\n",
    "        final_state = lstm_hidden.view(self.num_layers, 2, batch_size, self.hidden_dim)[-1]\n",
    "        h_1, h_2 = final_state[0], final_state[1]\n",
    "        # final_hidden_state = h_1 + h_2 \n",
    "         # Add both states (requires changes to the input size of first linear layer + attention layer)\n",
    "        final_hidden_state = torch.cat((h_1, h_2), 1)\n",
    "        logits = self.hidden2label(final_hidden_state)\n",
    "        # log_probs = F.log_softmax(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pad_features(tokenized_text, seq_length):\n",
    "    ''' Return features of tokenized_reviews, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(tokenized_text), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(tokenized_text):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# convert reviews to tokens\n",
    "def tokenize_all_text(embed_lookup, data):\n",
    "    # split each review into a list of words\n",
    "    words = [item['text'].split() for item in data.values()]\n",
    "\n",
    "    tokenized_text = []\n",
    "    for text in words:\n",
    "        ints = []\n",
    "        for word in text:\n",
    "            try:\n",
    "                idx = embed_lookup.key_to_index[word]\n",
    "            except: \n",
    "                idx = 0\n",
    "            ints.append(idx)\n",
    "        tokenized_text.append(ints)\n",
    "    \n",
    "    return tokenized_text\n",
    "\n",
    "# import Word2Vec loading capabilities\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Creating the model\n",
    "embed_lookup = KeyedVectors.load_word2vec_format('word2vec_model/GoogleNews-vectors-negative300-SLIM.bin', \n",
    "                                                 binary=True)\n",
    "# store pretrained vocab\n",
    "pretrained_words = []\n",
    "for word in embed_lookup.index_to_key:\n",
    "    pretrained_words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0      0      0      0      0  31722     78]\n",
      " [     0      0      0      0      0    132      3      9]\n",
      " [     0      0      0      0      0      0      0      0]\n",
      " [128719    814      0    134      4      9   2032   8748]\n",
      " [     0      0      0      0      0      0      0     78]\n",
      " [    83     34   6510      9   3042      0      9 137375]\n",
      " [   132    330     90     45     34   9593    545   8229]\n",
      " [    50   1748      9    708      4   1172  17670  77415]\n",
      " [     0      0      0      0      0      0      0   2873]\n",
      " [     0      0      0   1715   2962      0    245    116]\n",
      " [     0      0      0      0      0      0      0      0]\n",
      " [  4779     78     21   1090     56   4365   1183      9]\n",
      " [     0      0      0      0     78     83      9   6149]\n",
      " [   132    171      9   9519      0      9    527   5129]\n",
      " [   494     12    124   3887     12     38     45      2]\n",
      " [     0      0      0     78      3      9   1840      0]\n",
      " [  4779     78     21   1090      0      9  12761     56]\n",
      " [     0      0      3     25     24  33277      0     24]\n",
      " [     0      0    606      0    346    426  20392   7677]\n",
      " [     0      0      0      0      0      0      0     78]]\n",
      "[[    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0    78    17     9   904]\n",
      " [    0     0     0     0     0     0    78  1293]\n",
      " [    0     0     0     0     0     0  2873    10]\n",
      " [ 9065     9  4209 18225    78  3933  3027     3]\n",
      " [  596  1285     9 46637    36     0   116  2102]\n",
      " [    0     0     0     0     0     0     0   111]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     9 22248     0  2131   713   512     3]\n",
      " [   56   545  2599     4     0  3413   982    24]\n",
      " [    0     0   990  1400     0  2900     0 31722]\n",
      " [   43    22     0   476  9519     0 12761     9]\n",
      " [    0     0     0     0     0    78    21    14]\n",
      " [  512    17  3302     0     9    51     0  6161]\n",
      " [    0     0     0     0     0     0     0   132]\n",
      " [    0     0     0   132   171     9   875     0]\n",
      " [ 2873    43   125     9  1595     0     9 36622]\n",
      " [ 2873     9  8886  2035    38   187     0    53]\n",
      " [    0   525     0    86 34825     0  8357     0]\n",
      " [    0     0     0     0     0     0     0     0]]\n",
      "[0 1 0 2 0 1 1 0 1 0 1 1 1 1 0 1 1 2 1 0]\n",
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(192, 15) \n",
      "Validation set: \t(48, 15) \n",
      "Test set: \t\t(104, 15)\n"
     ]
    }
   ],
   "source": [
    "# LREC\n",
    "import json\n",
    "with open(\"../preprocess/lrec_split.json\") as f:\n",
    "    lrec_data = json.load(f)\n",
    "\n",
    "lrec_tokenized_text = tokenize_all_text(embed_lookup, lrec_data['train'])\n",
    "lrec_test_tokenized_text = tokenize_all_text(embed_lookup, lrec_data['test'])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "seq_length = 15\n",
    "\n",
    "lrec_train_features = pad_features(lrec_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(lrec_train_features)==len(lrec_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(lrec_train_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(lrec_train_features[:20,:8])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "lrec_test_features = pad_features(lrec_test_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(lrec_test_features)==len(lrec_test_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(lrec_test_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(lrec_test_features[:20,:8])\n",
    "\n",
    "\n",
    "lrec_train_labels = np.array([item['label'] for item in lrec_data['train'].values()])\n",
    "lrec_test_labels = np.array([item['label'] for item in lrec_data['test'].values()])\n",
    "\n",
    "print(lrec_test_labels[:20])\n",
    "\n",
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(lrec_train_features)*split_frac)\n",
    "lrec_train_x, lrec_valid_x = lrec_train_features[:split_idx], lrec_train_features[split_idx:]\n",
    "lrec_train_y, lrec_valid_y = lrec_train_labels[:split_idx], lrec_train_labels[split_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(lrec_train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(lrec_valid_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(lrec_test_features.shape))\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "lrec_train_data = TensorDataset(torch.from_numpy(lrec_train_x), torch.from_numpy(lrec_train_y))\n",
    "lrec_valid_data = TensorDataset(torch.from_numpy(lrec_valid_x), torch.from_numpy(lrec_valid_y))\n",
    "lrec_test_data = TensorDataset(torch.from_numpy(lrec_test_features), torch.from_numpy(lrec_test_labels))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 4\n",
    "\n",
    "# shuffling and batching data\n",
    "lrec_train_loader = DataLoader(lrec_train_data, shuffle=True, batch_size=batch_size)\n",
    "lrec_valid_loader = DataLoader(lrec_valid_data, shuffle=True, batch_size=batch_size)\n",
    "lrec_test_loader = DataLoader(lrec_test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMSentiment(\n",
      "  (embeddings): Embedding(299567, 300)\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (hidden2label): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "\n",
    "\n",
    "# lrec lstm\n",
    "\n",
    "vocab_size = len(pretrained_words)\n",
    "output_size = 3 # binary class (1 or 0)\n",
    "embedding_dim = len(embed_lookup[pretrained_words[0]]) # 300-dim vectors\n",
    "\n",
    "hidden_dim = 128\n",
    "\n",
    "batch_size = 4\n",
    "seq_length = 15\n",
    "\n",
    "num_layers =2\n",
    "\n",
    "lrec_lstm = BiLSTMSentiment(embed_lookup, vocab_size, output_size, embedding_dim,\n",
    "                   hidden_dim, batch_size, seq_length, num_layers)\n",
    "\n",
    "print(lrec_lstm)\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lrec_optimizer = torch.optim.Adam(lrec_lstm.parameters(), lr=lr, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train(net, train_loader, valid_loader, epochs, optimizer, patience = 5, print_every=100):\n",
    "\n",
    "    # # move model to GPU, if available\n",
    "    # if(train_on_gpu):\n",
    "    #     net.cuda()\n",
    "\n",
    "    counter = 0 # for printing\n",
    "    \n",
    "    # train for some number of epochs\n",
    "    net.train()\n",
    "    best_val_loss = 1e99\n",
    "    since_last_best = 0\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "\n",
    "            # if(train_on_gpu):\n",
    "            #     inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output = net(inputs)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Get validation loss\n",
    "        val_losses = []\n",
    "        net.eval()\n",
    "        for inputs, labels in valid_loader:\n",
    "\n",
    "            # if(train_on_gpu):\n",
    "            #     inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            output = net(inputs)\n",
    "            val_loss = criterion(output, labels)\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "        val_loss_epoch = np.mean(val_losses)\n",
    "        net.train()\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                \"Step: {}...\".format(counter),\n",
    "                \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                \"Val Loss: {:.6f}\".format(val_loss_epoch))\n",
    "        if val_loss_epoch < best_val_loss:\n",
    "            best_val_loss = val_loss_epoch\n",
    "        else:\n",
    "            since_last_best += 1\n",
    "        \n",
    "        if since_last_best == patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 48... Loss: 1.037308... Val Loss: 1.018558\n",
      "Epoch: 2/5... Step: 96... Loss: 0.838582... Val Loss: 0.985703\n",
      "Epoch: 3/5... Step: 144... Loss: 0.078073... Val Loss: 1.138642\n",
      "Epoch: 4/5... Step: 192... Loss: 0.107979... Val Loss: 1.263044\n",
      "Epoch: 5/5... Step: 240... Loss: 0.730394... Val Loss: 1.321250\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 5 # this is approx where I noticed the validation loss stop decreasing\n",
    "print_every = 10\n",
    "\n",
    "train(lrec_lstm, lrec_train_loader, lrec_valid_loader, epochs, lrec_optimizer, print_every=print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro F1: 0.490\n",
      "macro F1: 0.480\n",
      "weighted F1: 0.492\n",
      "\n",
      "micro precision: 0.490\n",
      "macro precision: 0.511\n",
      "weighted precision: 0.546\n",
      "\n",
      "micro recall: 0.490\n",
      "macro recall: 0.495\n",
      "weighted recall: 0.490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "pred_tensor = None\n",
    "label_tensor = None\n",
    "\n",
    "\n",
    "lrec_lstm.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in lrec_test_loader:\n",
    "\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = lrec_lstm(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output, labels)\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.argmax(output, dim=1)  # argmax\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "    if pred_tensor == None:\n",
    "        pred_tensor = pred\n",
    "    else:\n",
    "        pred_tensor = torch.cat((pred_tensor, pred), dim=-1)\n",
    "\n",
    "    if label_tensor == None:\n",
    "        label_tensor = labels\n",
    "    else:\n",
    "        label_tensor = torch.cat((label_tensor, labels), dim=-1)\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from torcheval.metrics.functional import multiclass_precision\n",
    "from torcheval.metrics.functional import multiclass_recall\n",
    "\n",
    "print(\"micro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted F1: {:.3f}\\n\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))\n",
    "\n",
    "print(\"micro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted precision: {:.3f}\\n\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))\n",
    "\n",
    "print(\"micro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted recall: {:.3f}\\n\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0    223     49  11534      0      0   4338   5408]\n",
      " [  8683    809      0   6776   2143      1   3221     30]\n",
      " [     0    897    359      0   1075      0     60  24442]\n",
      " [     0      0      0     43    400   2939     15      9]\n",
      " [     0      0      0      0   5687   2564   4281   1488]\n",
      " [   295     17   1931     41    373   2623      0   5779]\n",
      " [     0  18625   1337     22    630  20720      0      9]\n",
      " [     0    897    219      9 130013   1676      4      0]\n",
      " [    78    100    436   2129     56      0   2248    812]\n",
      " [  1780      0   3933   2251     45     14    219      0]\n",
      " [   295     17   1931     41    373   2623      0   5779]\n",
      " [     0    897    359      0   1075      0     60  24442]\n",
      " [     0    613    981      0    604    102      0   5043]\n",
      " [     0      0      0      0      0      0     43   8001]\n",
      " [     0      0      0      0      0      0      0      0]\n",
      " [     0  12430   2209   5043   3375    124   5871   2899]\n",
      " [     0    541   5317      0   1402      0    527   2323]\n",
      " [     0      0     78     42    100    436     14   1488]\n",
      " [     0   1426      0   6294      0 112061  15421   1524]\n",
      " [     0    223     49  11534      0      0   4338   5408]]\n",
      "[[  112  5437 37519     0   897  2158     0 36544]\n",
      " [   47  2352   187   530     0  3857  1009    50]\n",
      " [ 3784  5478   699 12449  1427     0  4338  8889]\n",
      " [    9  1724     0   137  4041   128 20668  1154]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0  6369 11935    24  6943     4     9   353]\n",
      " [    0     0     0     0     0     0    43   737]\n",
      " [    0     0     0     0    43   567    21   579]\n",
      " [   50 13721   286  2691   556   295  1074     9]\n",
      " [   78 27267   364    22     0  3042     0    40]\n",
      " [ 5094     0   593     0 16729     0  8051    17]\n",
      " [50083    17   250     9 29729     0     9  2773]\n",
      " [   43  2458   189  3988   132   124  5357   129]\n",
      " [  353     0  1036     0 18946    45  1210    36]\n",
      " [    0     0    43 13735    42     0  1977   930]\n",
      " [    0  6369    22  2922  2485  1337  2613     0]\n",
      " [    0     0     0     0   512    17     9  7402]\n",
      " [  100  6573     4  4729  3523     0   970  9705]\n",
      " [  295   719     0  6076  6943   500  5625     9]\n",
      " [    0     0     0     0    78  1089    53  2564]]\n",
      "[1 1 1 1 0 2 0 0 2 0 0 0 1 1 0 2 1 1 2 0]\n",
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(157, 15) \n",
      "Validation set: \t(40, 15) \n",
      "Test set: \t\t(82, 15)\n",
      "BiLSTMSentiment(\n",
      "  (embeddings): Embedding(299567, 300)\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (hidden2label): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ARC\n",
    "import json\n",
    "with open(\"../preprocess/arc_split.json\") as f:\n",
    "    arc_data = json.load(f)\n",
    "\n",
    "arc_tokenized_text = tokenize_all_text(embed_lookup, arc_data['train'])\n",
    "arc_test_tokenized_text = tokenize_all_text(embed_lookup, arc_data['test'])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "seq_length = 15\n",
    "\n",
    "arc_train_features = pad_features(arc_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(arc_train_features)==len(arc_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(arc_train_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(arc_train_features[:20,:8])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "arc_test_features = pad_features(arc_test_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(arc_test_features)==len(arc_test_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(arc_test_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(arc_test_features[:20,:8])\n",
    "\n",
    "\n",
    "arc_train_labels = np.array([item['label'] for item in arc_data['train'].values()])\n",
    "arc_test_labels = np.array([item['label'] for item in arc_data['test'].values()])\n",
    "\n",
    "print(arc_test_labels[:20])\n",
    "\n",
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(arc_train_features)*split_frac)\n",
    "arc_train_x, arc_valid_x = arc_train_features[:split_idx], arc_train_features[split_idx:]\n",
    "arc_train_y, arc_valid_y = arc_train_labels[:split_idx], arc_train_labels[split_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(arc_train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(arc_valid_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(arc_test_features.shape))\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "arc_train_data = TensorDataset(torch.from_numpy(arc_train_x), torch.from_numpy(arc_train_y))\n",
    "arc_valid_data = TensorDataset(torch.from_numpy(arc_valid_x), torch.from_numpy(arc_valid_y))\n",
    "arc_test_data = TensorDataset(torch.from_numpy(arc_test_features), torch.from_numpy(arc_test_labels))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 4\n",
    "\n",
    "# shuffling and batching data\n",
    "arc_train_loader = DataLoader(arc_train_data, shuffle=True, batch_size=batch_size)\n",
    "arc_valid_loader = DataLoader(arc_valid_data, shuffle=True, batch_size=batch_size)\n",
    "arc_test_loader = DataLoader(arc_test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# lrec lstm\n",
    "\n",
    "vocab_size = len(pretrained_words)\n",
    "output_size = 3 # binary class (1 or 0)\n",
    "embedding_dim = len(embed_lookup[pretrained_words[0]]) # 300-dim vectors\n",
    "\n",
    "hidden_dim = 128\n",
    "\n",
    "batch_size = 4\n",
    "seq_length = 15\n",
    "\n",
    "num_layers =2\n",
    "\n",
    "arc_lstm = BiLSTMSentiment(embed_lookup, vocab_size, output_size, embedding_dim,\n",
    "                   hidden_dim, batch_size, seq_length, num_layers)\n",
    "\n",
    "print(arc_lstm)\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "arc_optimizer = torch.optim.Adam(arc_lstm.parameters(), lr=lr, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 40... Loss: 1.269917... Val Loss: 1.046957\n",
      "Epoch: 2/5... Step: 80... Loss: 0.658942... Val Loss: 1.190822\n",
      "Epoch: 3/5... Step: 120... Loss: 0.119232... Val Loss: 1.264298\n",
      "Epoch: 4/5... Step: 160... Loss: 2.618878... Val Loss: 1.095488\n",
      "Epoch: 5/5... Step: 200... Loss: 0.096877... Val Loss: 1.131243\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 5 # this is approx where I noticed the validation loss stop decreasing\n",
    "print_every = 10\n",
    "\n",
    "train(arc_lstm, arc_train_loader, arc_valid_loader, epochs, arc_optimizer, print_every=print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro F1: 0.573\n",
      "macro F1: 0.564\n",
      "weighted F1: 0.576\n",
      "\n",
      "micro precision: 0.573\n",
      "macro precision: 0.554\n",
      "weighted precision: 0.594\n",
      "\n",
      "micro recall: 0.573\n",
      "macro recall: 0.598\n",
      "weighted recall: 0.573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "pred_tensor = None\n",
    "label_tensor = None\n",
    "\n",
    "\n",
    "arc_lstm.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in arc_test_loader:\n",
    "\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = arc_lstm(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output, labels)\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.argmax(output, dim=1)  # argmax\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "    if pred_tensor == None:\n",
    "        pred_tensor = pred\n",
    "    else:\n",
    "        pred_tensor = torch.cat((pred_tensor, pred), dim=-1)\n",
    "\n",
    "    if label_tensor == None:\n",
    "        label_tensor = labels\n",
    "    else:\n",
    "        label_tensor = torch.cat((label_tensor, labels), dim=-1)\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from torcheval.metrics.functional import multiclass_precision\n",
    "from torcheval.metrics.functional import multiclass_recall\n",
    "\n",
    "print(\"micro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted F1: {:.3f}\\n\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))\n",
    "\n",
    "print(\"micro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted precision: {:.3f}\\n\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))\n",
    "\n",
    "print(\"micro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted recall: {:.3f}\\n\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0   780     0 73009     1     0  9560]\n",
      " [    0     0     0  4699  4480     9  4516  1207]\n",
      " [    0     0     0     0     0     0     0  9660]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0  9660     9 19809     0     0]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0    78     3     9]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0    56]\n",
      " [    0     0     0     0  4328 86996  2629     0]\n",
      " [    0     0     0     0     0     0  4196     9]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0  7460]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0 23690     9   459]\n",
      " [  132    53    38  5838     9   389     0  1031]\n",
      " [    0     0     0     0     0     0     0     0]]\n",
      "[[     0      0      0  12646     25  24884  86996     12]\n",
      " [     0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0   4480      9]\n",
      " [     0      0      0      0      0      0    132    171]\n",
      " [     0    132     42     25    521     14    373     83]\n",
      " [     0      0      0      0      0    455     49   6009]\n",
      " [     0      0      0      0      0    132     42     38]\n",
      " [     0      0      0      0   1715      0   1891      0]\n",
      " [     0    116    235   1146    856     78      3   1982]\n",
      " [     0   5141      9    390      0 138536  32197    160]\n",
      " [     0      0      0      0      0    132      0  11666]\n",
      " [     0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0    856    132]\n",
      " [     0      0    455   3405    737   3704      9    100]\n",
      " [     0      0      0      0      0      0      0   5812]\n",
      " [     0      0      0      0      0    132    141     54]\n",
      " [     0      0      0      0      0   5838     95     49]\n",
      " [     0      0   2873      9    917   2308      9   1915]\n",
      " [     0      0      0      0    680      9   4370      0]\n",
      " [     0      0      0      0      0      0      0      0]]\n",
      "[0 0 0 2 2 2 0 1 0 2 2 0 0 2 2 0 2 0 0 0]\n",
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(333, 15) \n",
      "Validation set: \t(84, 15) \n",
      "Test set: \t\t(179, 15)\n",
      "BiLSTMSentiment(\n",
      "  (embeddings): Embedding(299567, 300)\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (hidden2label): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# nu\n",
    "import json\n",
    "with open(\"../preprocess/nu_split.json\") as f:\n",
    "    nu_data = json.load(f)\n",
    "\n",
    "nu_tokenized_text = tokenize_all_text(embed_lookup, nu_data['train'])\n",
    "nu_test_tokenized_text = tokenize_all_text(embed_lookup, nu_data['test'])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "seq_length = 15\n",
    "\n",
    "nu_train_features = pad_features(nu_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(nu_train_features)==len(nu_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(nu_train_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(nu_train_features[:20,:8])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "nu_test_features = pad_features(nu_test_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(nu_test_features)==len(nu_test_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(nu_test_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(nu_test_features[:20,:8])\n",
    "\n",
    "\n",
    "nu_train_labels = np.array([item['label'] for item in nu_data['train'].values()])\n",
    "nu_test_labels = np.array([item['label'] for item in nu_data['test'].values()])\n",
    "\n",
    "print(nu_test_labels[:20])\n",
    "\n",
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(nu_train_features)*split_frac)\n",
    "nu_train_x, nu_valid_x = nu_train_features[:split_idx], nu_train_features[split_idx:]\n",
    "nu_train_y, nu_valid_y = nu_train_labels[:split_idx], nu_train_labels[split_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(nu_train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(nu_valid_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(nu_test_features.shape))\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "nu_train_data = TensorDataset(torch.from_numpy(nu_train_x), torch.from_numpy(nu_train_y))\n",
    "nu_valid_data = TensorDataset(torch.from_numpy(nu_valid_x), torch.from_numpy(nu_valid_y))\n",
    "nu_test_data = TensorDataset(torch.from_numpy(nu_test_features), torch.from_numpy(nu_test_labels))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 4\n",
    "\n",
    "# shuffling and batching data\n",
    "nu_train_loader = DataLoader(nu_train_data, shuffle=True, batch_size=batch_size)\n",
    "nu_valid_loader = DataLoader(nu_valid_data, shuffle=True, batch_size=batch_size)\n",
    "nu_test_loader = DataLoader(nu_test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# lrec lstm\n",
    "\n",
    "vocab_size = len(pretrained_words)\n",
    "output_size = 3 # binary class (1 or 0)\n",
    "embedding_dim = len(embed_lookup[pretrained_words[0]]) # 300-dim vectors\n",
    "\n",
    "hidden_dim = 128\n",
    "\n",
    "batch_size = 4\n",
    "seq_length = 15\n",
    "\n",
    "num_layers =2\n",
    "\n",
    "nu_lstm = BiLSTMSentiment(embed_lookup, vocab_size, output_size, embedding_dim,\n",
    "                   hidden_dim, batch_size, seq_length, num_layers)\n",
    "\n",
    "print(nu_lstm)\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "nu_optimizer = torch.optim.Adam(nu_lstm.parameters(), lr=lr, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 84... Loss: 1.418625... Val Loss: 1.091758\n",
      "Epoch: 2/5... Step: 168... Loss: 0.544706... Val Loss: 1.056411\n",
      "Epoch: 3/5... Step: 252... Loss: 0.140157... Val Loss: 1.025819\n",
      "Epoch: 4/5... Step: 336... Loss: 1.255961... Val Loss: 1.084976\n",
      "Epoch: 5/5... Step: 420... Loss: 1.570338... Val Loss: 1.040039\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 5 # this is approx where I noticed the validation loss stop decreasing\n",
    "print_every = 10\n",
    "\n",
    "train(nu_lstm, nu_train_loader, nu_valid_loader, epochs, nu_optimizer, print_every=print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro F1: 0.654\n",
      "macro F1: 0.607\n",
      "weighted F1: 0.664\n",
      "\n",
      "micro precision: 0.654\n",
      "macro precision: 0.606\n",
      "weighted precision: 0.680\n",
      "\n",
      "micro recall: 0.654\n",
      "macro recall: 0.620\n",
      "weighted recall: 0.654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "pred_tensor = None\n",
    "label_tensor = None\n",
    "\n",
    "\n",
    "nu_lstm.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in nu_test_loader:\n",
    "\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = nu_lstm(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output, labels)\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.argmax(output, dim=1)  # argmax\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "    if pred_tensor == None:\n",
    "        pred_tensor = pred\n",
    "    else:\n",
    "        pred_tensor = torch.cat((pred_tensor, pred), dim=-1)\n",
    "\n",
    "    if label_tensor == None:\n",
    "        label_tensor = labels\n",
    "    else:\n",
    "        label_tensor = torch.cat((label_tensor, labels), dim=-1)\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from torcheval.metrics.functional import multiclass_precision\n",
    "from torcheval.metrics.functional import multiclass_recall\n",
    "\n",
    "print(\"micro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted F1: {:.3f}\\n\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))\n",
    "\n",
    "print(\"micro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted precision: {:.3f}\\n\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))\n",
    "\n",
    "print(\"micro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3).item()))\n",
    "print(\"macro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3, average='macro').item()))\n",
    "print(\"weighted recall: {:.3f}\\n\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=3, average='weighted').item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   986      9   2887     12    390  58549     22     37]\n",
      " [     0     25  22694      9    770      0     78  72206]\n",
      " [     0  15370  10297  15760   1504      0   1444      0]\n",
      " [     9  24325   1947      8   2041      0      9    271]\n",
      " [     9   6398      2   6837     78   1599      0    192]\n",
      " [  5097      0   4408      0   1015      0  11542   3677]\n",
      " [    40   4932      0   1218   2000     22     37      2]\n",
      " [    34    857      0      9   4588      0      0  13080]\n",
      " [  4818     35   1471   5695      0   9577  21774      9]\n",
      " [    66   3411      3      0   8561      0 231574    179]\n",
      " [    34   2093   3980      0   7712      0  60560  10492]\n",
      " [    25   1427   2000  22915 104856 231574      1  36464]\n",
      " [  1682     24   7558   7110      0    129      0    125]\n",
      " [     0      0      0     34   4094      0     60   5426]\n",
      " [     0      0      9   8190    483     16      9   1931]\n",
      " [     0    957      9   8521   3936      0  80045  37286]\n",
      " [     0   5526   2878   3106    160   3079      0   2108]\n",
      " [  2975     34     17   1528      0    132   1206   3475]\n",
      " [   986      0     22     37  37123   3199      0   9385]\n",
      " [     0    142  10176 112503    676    554      0     78]]\n",
      "[[    67     17     49    488  10150      0   1949   9666]\n",
      " [     9    655   3383      0  34490 147937   3988     27]\n",
      " [     0      0     34   4094      9   1300  17705      1]\n",
      " [     1      9      0  30269      9   1252  12674   9174]\n",
      " [  1379   6717  11660     17   1409      0   7580   3422]\n",
      " [  6581      2     34   1366     73   5695   2956   6610]\n",
      " [     0      0      0  13223     16  15455   1613    130]\n",
      " [    10  28039   4317    997  80045  85080      0 134972]\n",
      " [     1   2411   2313    124    554  26267     82      4]\n",
      " [     0      0      0      0   1408      0     25  27492]\n",
      " [     9      0   9027   8699      0      9   4173      2]\n",
      " [   664      9   3917    297      1   3260      9    680]\n",
      " [     0   1161      1      9    389      0  15370  10297]\n",
      " [     0      0      0      0      0   1553   1207      3]\n",
      " [     0      0      0    681   5843     14      9    189]\n",
      " [     0      0      0      0      0      0      0      0]\n",
      " [   213      9  26928      0      0   5395      3   9215]\n",
      " [    66    606    819      9  13064   2135  12987      0]\n",
      " [  5725    365      9      0   3420   1329  15760      9]\n",
      " [     0      9     49   9642     17    841      0   3277]]\n",
      "[0 3 3 0 0 3 0 3 0 0 0 2 0 0 0 0 0 1 0 3]\n",
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(703, 15) \n",
      "Validation set: \t(176, 15) \n",
      "Test set: \t\t(378, 15)\n",
      "BiLSTMSentiment(\n",
      "  (embeddings): Embedding(299567, 300)\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (hidden2label): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../preprocess/arg_split.json\") as f:\n",
    "    arg_data = json.load(f)\n",
    "\n",
    "arg_tokenized_text = tokenize_all_text(embed_lookup, arg_data['train'])\n",
    "arg_test_tokenized_text = tokenize_all_text(embed_lookup, arg_data['test'])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "seq_length = 15\n",
    "\n",
    "arg_train_features = pad_features(arg_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(arg_train_features)==len(arg_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(arg_train_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(arg_train_features[:20,:8])\n",
    "\n",
    "# Test your implementation!\n",
    "\n",
    "arg_test_features = pad_features(arg_test_tokenized_text, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(arg_test_features)==len(arg_test_tokenized_text), \"Features should have as many rows as reviews.\"\n",
    "assert len(arg_test_features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 8 values of the first 20 batches \n",
    "print(arg_test_features[:20,:8])\n",
    "\n",
    "\n",
    "arg_train_labels = np.array([item['label'] for item in arg_data['train'].values()])\n",
    "arg_test_labels = np.array([item['label'] for item in arg_data['test'].values()])\n",
    "\n",
    "print(arg_test_labels[:20])\n",
    "\n",
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(arg_train_features)*split_frac)\n",
    "arg_train_x, arg_valid_x = arg_train_features[:split_idx], arg_train_features[split_idx:]\n",
    "arg_train_y, arg_valid_y = arg_train_labels[:split_idx], arg_train_labels[split_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(arg_train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(arg_valid_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(arg_test_features.shape))\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "arg_train_data = TensorDataset(torch.from_numpy(arg_train_x), torch.from_numpy(arg_train_y))\n",
    "arg_valid_data = TensorDataset(torch.from_numpy(arg_valid_x), torch.from_numpy(arg_valid_y))\n",
    "arg_test_data = TensorDataset(torch.from_numpy(arg_test_features), torch.from_numpy(arg_test_labels))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 4\n",
    "\n",
    "# shuffling and batching data\n",
    "arg_train_loader = DataLoader(arg_train_data, shuffle=True, batch_size=batch_size)\n",
    "arg_valid_loader = DataLoader(arg_valid_data, shuffle=True, batch_size=batch_size)\n",
    "arg_test_loader = DataLoader(arg_test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# nu lstm\n",
    "\n",
    "vocab_size = len(pretrained_words)\n",
    "output_size = 4 # binary class (1 or 0)\n",
    "embedding_dim = len(embed_lookup[pretrained_words[0]]) # 300-dim vectors\n",
    "\n",
    "hidden_dim = 128\n",
    "\n",
    "batch_size = 4\n",
    "seq_length = 15\n",
    "\n",
    "num_layers =2\n",
    "\n",
    "arg_lstm = BiLSTMSentiment(embed_lookup, vocab_size, output_size, embedding_dim,\n",
    "                   hidden_dim, batch_size, seq_length, num_layers)\n",
    "\n",
    "print(arg_lstm)\n",
    "\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "arg_optimizer = torch.optim.Adam(arg_lstm.parameters(), lr=lr, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 176... Loss: 1.488478... Val Loss: 1.226024\n",
      "Epoch: 2/5... Step: 352... Loss: 0.631088... Val Loss: 1.319970\n",
      "Epoch: 3/5... Step: 528... Loss: 0.395240... Val Loss: 1.074261\n",
      "Epoch: 4/5... Step: 704... Loss: 0.209982... Val Loss: 1.140975\n",
      "Epoch: 5/5... Step: 880... Loss: 0.847276... Val Loss: 0.834745\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 5 # this is approx where I noticed the validation loss stop decreasing\n",
    "print_every = 10\n",
    "\n",
    "train(arg_lstm, arg_train_loader, arg_valid_loader, epochs, arg_optimizer, print_every=print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro F1: 0.659\n",
      "macro F1: 0.556\n",
      "weighted F1: 0.662\n",
      "\n",
      "micro precision: 0.659\n",
      "macro precision: 0.544\n",
      "weighted precision: 0.666\n",
      "\n",
      "micro recall: 0.659\n",
      "macro recall: 0.572\n",
      "weighted recall: 0.659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "pred_tensor = None\n",
    "label_tensor = None\n",
    "\n",
    "\n",
    "arg_lstm.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in arg_test_loader:\n",
    "\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = arg_lstm(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output, labels)\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.argmax(output, dim=1)  # argmax\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "    if pred_tensor == None:\n",
    "        pred_tensor = pred\n",
    "    else:\n",
    "        pred_tensor = torch.cat((pred_tensor, pred), dim=-1)\n",
    "\n",
    "    if label_tensor == None:\n",
    "        label_tensor = labels\n",
    "    else:\n",
    "        label_tensor = torch.cat((label_tensor, labels), dim=-1)\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from torcheval.metrics.functional import multiclass_precision\n",
    "from torcheval.metrics.functional import multiclass_recall\n",
    "\n",
    "print(\"micro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=4).item()))\n",
    "print(\"macro F1: {:.3f}\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=4, average='macro').item()))\n",
    "print(\"weighted F1: {:.3f}\\n\".format(multiclass_f1_score(pred_tensor, label_tensor, num_classes=4, average='weighted').item()))\n",
    "\n",
    "print(\"micro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=4).item()))\n",
    "print(\"macro precision: {:.3f}\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=4, average='macro').item()))\n",
    "print(\"weighted precision: {:.3f}\\n\".format(multiclass_precision(pred_tensor, label_tensor, num_classes=4, average='weighted').item()))\n",
    "\n",
    "print(\"micro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=4).item()))\n",
    "print(\"macro recall: {:.3f}\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=4, average='macro').item()))\n",
    "print(\"weighted recall: {:.3f}\\n\".format(multiclass_recall(pred_tensor, label_tensor, num_classes=4, average='weighted').item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".shine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
